{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2 - Parte 2\n",
    "\n",
    "### Modelos no paramétricos\n",
    "\n",
    "### 2019-I\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomado de https://github.com/rramosp/mooc-grader\n",
    "from Autentication import *#python 3\n",
    "import inspect, urllib\n",
    "html, auth_code, userinfo = google_authenticate(PORT_NUMBER=8080)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer integrante:\n",
    "Nombre: Alejandro Castaño Rojas\n",
    "\n",
    "### Segundo integrante:\n",
    "Nombre: Angélica Arroyave Mendoza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "#Evitar algunas advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "\n",
    "Usaremos el dataset iris para el problema de clasificación, desde la librería sklearn. En el UCI Machine Learning Repository se encuentra más información en el siguiente [link](https://archive.ics.uci.edu/ml/datasets/iris) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos la bd iris desde el dataset de sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "\n",
    "X, Y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda las siguientes preguntas: \n",
    "\n",
    "1.1 ¿Cu&aacute;ntas clases tiene el problema?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "El número de clases que tene el problema son: 3\n"
     ]
    }
   ],
   "source": [
    "clases = np.unique(Y)\n",
    "print(clases)\n",
    "print(\"El número de clases que tene el problema son:\", clases.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 ¿Cu&aacute;ntas caracter&iacute;sticas tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de caraterísticas que tiene el problema son:  4\n"
     ]
    }
   ],
   "source": [
    "muestras, caracteristicas = X.shape\n",
    "print(\"El número de caraterísticas que tiene el problema son: \", caracteristicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 ¿Cuántas muestras tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de muestras que tiene el problema son:  150\n"
     ]
    }
   ],
   "source": [
    "print(\"El número de muestras que tiene el problema son: \", muestras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 ¿Cu&aacute;ntas muestras por cada clase hay en la base de datos?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 50, 1: 50, 2: 50})\n",
      "El número de muestras para la clase 0 es de 50 muestras. El número de muestras para la clase 1 es de 50 muestras. El número de muestras para la clase 2 es de 50 muestras\n"
     ]
    }
   ],
   "source": [
    "numeroClasesPorMuestra = collections.Counter(Y)\n",
    "\n",
    "print(numeroClasesPorMuestra)\n",
    "print(\"El número de muestras para la clase 0 es de 50 muestras. El número de muestras para la clase 1 es de 50 muestras. El número de muestras para la clase 2 es de 50 muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Completar código KNN\n",
    "\n",
    "Analice los siguientes métodos de la teoría vista para los modelos de *K-vecinos más cercanos (KNN)* y complete el código del método KNN.\n",
    "\n",
    "<b>Nota</b>: Para el cáculo de la distancia entre vectores tienen dos opciones, usar la función la distancia euclidiana `scipy.spatial.distance.euclidean`([Ejemplo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html)) o usar la función `numpy.linalg.norm`([Ejemplo](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)). Revisen la documentación para comprender su uso. También serán de utilidad las funciones `numpy.sort` y `numpy.argsort`.\n",
    "\n",
    "\n",
    "<b>Nota</b>: Para el cáculo de la distancia entre vectores tienen dos opciones, usar la función scipy.spatial.distance.euclidean o usar la función numpy.linalg.norm. <b>Revisen la documentación </b> para comprender su uso. También serán de utilidad las funciones numpy.sort y numpy.argsort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = [1,2,3,1,2,1,1,1,3,2,2,1];\n",
    "b = Counter(a).most_common(1);\n",
    "#b = Counter(a)\n",
    "claseModa, repeticion = b[0]\n",
    "claseModa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import operator\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#Para calcular el error en los problemas de clasificación\n",
    "def KNN_regression(X_train, Y_train, x_test, k):\n",
    "    distances = []\n",
    "    muestras, caracteristicas = X_train.shape\n",
    "    for i in range(muestras):\n",
    "        distances.append(distance.euclidean(X_train[i], x_test))\n",
    "    aux_distances = distances.copy()\n",
    "    aux_distances.sort()\n",
    "    suma_y = 0\n",
    "    for i in range(k):\n",
    "        rel_pos = distances.index(aux_distances[i])\n",
    "        suma_y += Y_train[rel_pos]\n",
    "    prom_y = suma_y/k # Aquí ya tenemos el promedio :D\n",
    "    return prom_y\n",
    "\n",
    "#Para calcular el error en los problemas de clasificación\n",
    "def KNN_classification(X_train, Y_train, x_test, k):\n",
    "    distances = []\n",
    "    muestras, caracteristicas = X_train.shape\n",
    "    for i in range(muestras):\n",
    "        distances.append((distance.euclidean(X_train[i], x_test), i))\n",
    "    aux_distances = distances.copy()\n",
    "    aux_distances = sorted(aux_distances,key=lambda x: x[0])\n",
    "    Y_selected = np.zeros(k);\n",
    "    for i in range(k):\n",
    "        rel_pos = distances.index(aux_distances[i])\n",
    "        Y_selected[i] = Y_train[aux_distances[i][1]]\n",
    "    moda_y = mode(Y_selected, axis=None)[0][0]\n",
    "    return moda_y\n",
    "\n",
    "def ErrorClas(Y_lest, Y):\n",
    "    error = 1 - np.sum(Y_lest == Y)/len(Y)\n",
    "    \n",
    "    return error\n",
    "\n",
    "\n",
    "def KNN(X_train, Y_train, X_val, k, tipo):\n",
    "    \n",
    "    #X_train es la matriz con las muestras de entrenamiento\n",
    "    #Y_train es un vector con los valores de salida pra cada una de las muestras de entrenamiento\n",
    "    #X_val es la matriz con las muestras de validación\n",
    "    #tipo es una bandera que indica si el problema es de regresión o de clasificación.\n",
    "    tipo = tipo\n",
    "    k = k    #Parámetro k que equivale al número de vecinos a tener en cuenta para resolver el problema de\n",
    "               #predicción de la variable de salida\n",
    "    Nt = len(X_val)\n",
    "    Y_test = np.zeros(Nt)\n",
    "    for i in range(Nt):\n",
    "        if(tipo == 1):\n",
    "            Y_test[i] = KNN_classification(X_train, Y_train, X_val[i], k)\n",
    "        if(tipo==0):\n",
    "            Y_test[i] = KNN_regression(X_train, Y_train, X_val[i], k)\n",
    "    \n",
    "    \n",
    "    return Y_test #Debe retornar un vector que contenga las predicciones para cada una de las muestras en X_val, en el mismo orden.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Una vez haya completado el codigo del método de KNN, ejecute varias veces el proceso de entrenamiento y evaluación cambiando el parametro $k$, el cual es el numero de vecinos, y complete la siguiente tabla con los valores del error de clasificación obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error durante la prueba = 0.2763157894736842+- 0.0842516347030638\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy.matlib as mt\n",
    "\n",
    "N = np.size(X,0)\n",
    "\n",
    "#Validamos el modelo\n",
    "random.seed(1)\n",
    "Xtrain_size = 0\n",
    "Xtest_size = 0\n",
    "Error = np.zeros(4)\n",
    "for j in range(4):\n",
    "        \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.25)\n",
    "    \n",
    "    #Normalizamos los datos\n",
    "    \n",
    "    media = np.mean(Xtrain)\n",
    "    desvia = np.std(Xtrain)\n",
    "    Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "    Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "    tipo = 1\n",
    "    #Tipo 1  es para clasificación Tipo 2 es para regresión\n",
    "    Yest = KNN(Xtrain, Ytrain, Xtest, 7, tipo)#Complete con el llamado apropiado de la función que Uds diseñaron\n",
    "    \n",
    "    #Evaluamos las predicciones del modelo con los datos de test\n",
    "    Error[j] = ErrorClas(Yest,Ytest)\n",
    "    Xtrain_size = Xtrain.shape[0]\n",
    "    Xtest_size = Xtest.shape[0]\n",
    "print('\\nError durante la prueba = ' + str(np.mean(Error)) + '+- ' + str(np.std(Error)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda:\n",
    "\n",
    "3.1 ¿Qué metodología de validación se usa en el experimento?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La metodología de validación que se utiliza es Bootstraping dado que se le esta asignando un 25% de datos para las pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 ¿Cuántas muestras se usan para el entrenamiento?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de muestras que se usan para el entrenamiento son:  112\n"
     ]
    }
   ],
   "source": [
    "print(\"El número de muestras que se usan para el entrenamiento son: \", Xtrain_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 ¿Cuántas muestras se usan para la validación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de muestras que se usan para la validación son:  38\n"
     ]
    }
   ],
   "source": [
    "print(\"El número de muestras que se usan para la validación son: \", Xtest_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbf0478ae3c49ffa42c7f321157d016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de vecinos' : pd.Series(['1', '2', '3', '4', '5', '6', '7'])})\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types[\"Desviación estándar del error\"] = \"\"\n",
    "df_types.set_index(['Numero de vecinos'], inplace=True)\n",
    "df_types[\"Error_Prueba\"][0] = \"0.2039\"\n",
    "df_types[\"Error_Prueba\"][1] = \"0.2697\"\n",
    "df_types[\"Error_Prueba\"][2] = \"0.2697\"\n",
    "df_types[\"Error_Prueba\"][3] = \"0.2828\"\n",
    "df_types[\"Error_Prueba\"][4] = \"0.2697\"\n",
    "df_types[\"Error_Prueba\"][5] = \"0.2763\"\n",
    "df_types[\"Error_Prueba\"][6] = \"0.2763\"\n",
    "df_types[\"Desviación estándar del error\"][0] = \"0.1137\"\n",
    "df_types[\"Desviación estándar del error\"][1] = \"0.088\"\n",
    "df_types[\"Desviación estándar del error\"][2] = \"0.086\"\n",
    "df_types[\"Desviación estándar del error\"][3] = \"0.0752\"\n",
    "df_types[\"Desviación estándar del error\"][4] = \"0.088\"\n",
    "df_types[\"Desviación estándar del error\"][5] = \"0.0842\"\n",
    "df_types[\"Desviación estándar del error\"][6] = \"0.0842\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Desviación estándar del error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de vecinos</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Error_Prueba Desviación estándar del error\n",
       "Numero de vecinos                                           \n",
       "1                       0.2039                        0.1137\n",
       "2                       0.2697                         0.088\n",
       "3                       0.2697                         0.086\n",
       "4                       0.2828                        0.0752\n",
       "5                       0.2697                         0.088\n",
       "6                       0.2763                        0.0842\n",
       "7                       0.2763                        0.0842"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "A continuación debe completar el código del método parzen para resolver problemas de clasificación con el modelo ventana de Parzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna los índices en donde se encuentra la información de cada clase\n",
    "def split_data(X_values, Y_values):\n",
    "   possible_values = np.unique(Y_values)\n",
    "   data_segmentation_dict = {}\n",
    "   data_segmentation_result = []\n",
    "   for i in possible_values:\n",
    "       data_segmentation_dict[i] = []\n",
    "   for i in range(X_values.shape[0]):\n",
    "       data_segmentation_dict[Y_values[i]].append(i)\n",
    "   for key, value in data_segmentation_dict.items():\n",
    "       data_segmentation_result.append(value)\n",
    "   return data_segmentation_result\n",
    "\n",
    "def construct_partial_data(full_data, segmentation_data_indexes):\n",
    "   partial_data = []\n",
    "   for i in range(full_data.shape[0]):\n",
    "       if i in segmentation_data_indexes:\n",
    "           partial_data.append(full_data[i])\n",
    "   return partial_data\n",
    "\n",
    "def find_max_probability(probability_array):\n",
    "   arr_copy = []\n",
    "   for elem in probability_array:\n",
    "       arr_copy.append(elem)\n",
    "   probability_array.sort()\n",
    "   #print(\"probability_array\",probability_array)\n",
    "   #print(\"arr_copy\",arr_copy)\n",
    "   for p in range(len(arr_copy)):\n",
    "       if probability_array[len(probability_array)-1] == arr_copy[p]:\n",
    "           return p\n",
    "\n",
    "#Calcula el kernel gaussiano de x\n",
    "def kernel_gaussiano(x):\n",
    "   return np.exp((-0.5)*x**2)\n",
    "\n",
    "def ParzenWindow(x,Data,h):\n",
    "   h = h\n",
    "   #Ns = Data.shape[0]\n",
    "   Ns = len(Data)\n",
    "   suma = 0\n",
    "   for k in range(Ns):\n",
    "       u = sc.spatial.distance.euclidean(x,Data[k])\n",
    "       suma += kernel_gaussiano(u/h)\n",
    "   return suma\n",
    "\n",
    "def ParzenClass(X_train, Y_train, X_val, ancho_h):\n",
    "   Yest = np.zeros(X_val.shape[0])\n",
    "   h = ancho_h\n",
    "   X_val_dict = {}\n",
    "   # Inicializando valores de probabilidad por cada clase\n",
    "   Datas = split_data(X_train, Y_train)\n",
    "   partial_datas = []\n",
    "   for i in range(len(Datas)):\n",
    "       partial_datas.append(construct_partial_data(X_train, Datas[i]))\n",
    "   for i in range(X_val.shape[0]):\n",
    "       X_val_dict[i] = np.zeros(len(np.unique(Y_train)))\n",
    "   for i in range(0,X_val.shape[0]):\n",
    "       for j in range(len(Datas)):\n",
    "           X_val_dict[i][j] = ParzenWindow(X_val[i], partial_datas[j], h)\n",
    "       Yest[i] = find_max_probability(X_val_dict[i])\n",
    "   return Yest #Debe retornar un vector que contenga las predicciones para cada una de las muestras en X_val, en el mismo orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Ahora debe resolver el mismo problema de clasificación con el método ventana de Parzen. Complete el código ejecute las pruebas para diferentes valores de $h$ y llene la siguiente tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error durante la prueba = 0.2216880341880342+-0.04332854434165311\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "\n",
    "#Validamos el modelo\n",
    "random.seed(1)\n",
    "Error = np.zeros(4)\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "j = 0\n",
    "muestras_entrenamiento = []\n",
    "muestras_prueba = []\n",
    "for train, test in skf.split(X, Y):\n",
    "    Xtrain = X[train,:]\n",
    "    Ytrain = Y[train]\n",
    "    Xtest = X[test,:]\n",
    "    Ytest = Y[test]\n",
    "    \n",
    "    muestras_entrenamiento.append(Xtrain.shape[0])\n",
    "    muestras_prueba.append(Xtest.shape[0])\n",
    "    \n",
    "    #Normalizamos los datos\n",
    "    media = np.mean(Xtrain)\n",
    "    desvia = np.std(Xtrain)\n",
    "    Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "    Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "    \n",
    "    Yest = ParzenClass(Xtrain, Ytrain, Xtest, 0.1)#Complete con el llamado apropiado de la función que Uds diseñaron\n",
    "    \n",
    "    #Evaluamos las predicciones del modelo con los datos de test\n",
    "    #print(\"Yest\", Yest)\n",
    "    #rint(\"Ytest\", Ytest)\n",
    "    Error[j] = ErrorClas(Yest,Ytest)\n",
    "    j += 1\n",
    "print('\\nError durante la prueba = ' + str(np.mean(Error)) + '+-' + str(np.std(Error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda:\n",
    "    \n",
    "5.1 ¿Qué metodología de validación se usó en la simulación?:\n",
    "\n",
    "**R//** La metodología de validación utilizada es la validación cruzada usando 4 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 ¿Cuántas muestras se usan para el entrenamiento?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el entrenamiento se usaron [111, 111, 114, 114] muestras de entrenamiento\n"
     ]
    }
   ],
   "source": [
    "print('Para el entrenamiento se usaron', muestras_entrenamiento, 'muestras de entrenamiento')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 ¿Cuántas muestras se usan para la validación?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el entrenamiento se usaron [39, 39, 36, 36] muestras de validación\n"
     ]
    }
   ],
   "source": [
    "print('Para el entrenamiento se usaron', muestras_prueba, 'muestras de validación')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d37bb47b6f4f7d9085a38e0dd60f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types2 = pd.DataFrame({\n",
    "   'Tamano de ventana' : pd.Series(['0.05', '0.1', '0.5', '1', '2', '5', '10'])})\n",
    "df_types2[\"Error_Prueba\"] = \"\"\n",
    "df_types2[\"Desviación estándar del error\"] = \"\"\n",
    "df_types2.set_index(['Tamano de ventana'], inplace=True)\n",
    "df_types2[\"Error_Prueba\"][0] = \"0.221688034188\"\n",
    "df_types2[\"Desviación estándar del error\"][0] = \"0.0433285443417\"\n",
    "df_types2[\"Error_Prueba\"][1] = \"0.222\"\n",
    "df_types2[\"Desviación estándar del error\"][1] = \"0.043\"\n",
    "df_types2[\"Error_Prueba\"][2] = \"0.281517094017\"\n",
    "df_types2[\"Desviación estándar del error\"][2] = \"0.0402133970489\"\n",
    "df_types2[\"Error_Prueba\"][3] = \"0.280982905983\"\n",
    "df_types2[\"Desviación estándar del error\"][3] = \"0.0314581877443\"\n",
    "df_types2[\"Error_Prueba\"][4] = \"0.241987179487\"\n",
    "df_types2[\"Desviación estándar del error\"][4] = \"0.0584661421377\"\n",
    "df_types2[\"Error_Prueba\"][5] = \"0.221688034188\"\n",
    "df_types2[\"Desviación estándar del error\"][5] = \"0.0469690733646\"\n",
    "df_types2[\"Error_Prueba\"][6] = \"0.221688034188\"\n",
    "df_types2[\"Desviación estándar del error\"][6] = \"0.0469690733646\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types2, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Prueba</th>\n",
       "      <th>Desviación estándar del error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tamano de ventana</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.221688034188</td>\n",
       "      <td>0.0433285443417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.281517094017</td>\n",
       "      <td>0.0402133970489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.280982905983</td>\n",
       "      <td>0.0314581877443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241987179487</td>\n",
       "      <td>0.0584661421377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.221688034188</td>\n",
       "      <td>0.0469690733646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.221688034188</td>\n",
       "      <td>0.0469690733646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Error_Prueba Desviación estándar del error\n",
       "Tamano de ventana                                              \n",
       "0.05               0.221688034188               0.0433285443417\n",
       "0.1                         0.222                         0.043\n",
       "0.5                0.281517094017               0.0402133970489\n",
       "1                  0.280982905983               0.0314581877443\n",
       "2                  0.241987179487               0.0584661421377\n",
       "5                  0.221688034188               0.0469690733646\n",
       "10                 0.221688034188               0.0469690733646"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
